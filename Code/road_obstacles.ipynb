{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0156acc",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip uninstall torch torchvision torchaudio ultralytics -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f434abbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f434abbf",
        "outputId": "0454b244-f7f6-43a7-f279-c692608c9010"
      },
      "outputs": [],
      "source": [
        "%pip install gdown ultralytics tqdm pycocotools opencv-python\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XvlnNHRDnZc6",
      "metadata": {
        "id": "XvlnNHRDnZc6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "MERGED_PATH = 'merged_dataset'\n",
        "COCO_PATH = 'coco2017'\n",
        "RDD_PATH = 'RDD_SPLIT'\n",
        "\n",
        "CLASSES = [\n",
        "    'car', 'pedestrian', 'bicycle', 'truck',\n",
        "    'longitudinal crack', 'alligator crack', 'transverse crack', 'other corruption', 'pothole'\n",
        "]\n",
        "\n",
        "COCO_CATEGORY_MAPPING = {\n",
        "    3: 0,  # car\n",
        "    1: 1,  # pedestrian\n",
        "    2: 2,  # bicycle\n",
        "    8: 3   # truck\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a89bbc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a89bbc2",
        "outputId": "2f6bc945-ec7d-467c-b588-890ce718b12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing COCO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying COCO images: 100%|██████████| 69260/69260 [03:43<00:00, 310.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing RDD2022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying train images: 100%|██████████| 26869/26869 [03:23<00:00, 131.75it/s]\n",
            "Copying test images: 100%|██████████| 5758/5758 [00:44<00:00, 127.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting dataset\n",
            "Merged dataset ready at: merged_dataset\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(f\"{MERGED_PATH}/images\", exist_ok=True)\n",
        "os.makedirs(f\"{MERGED_PATH}/labels\", exist_ok=True)\n",
        "\n",
        "image_paths = []\n",
        "\n",
        "# Converting COCO to YOLO format\n",
        "print(\"Processing COCO\")\n",
        "coco_images_dir = os.path.join(COCO_PATH, 'train2017')\n",
        "coco_annotations_file = os.path.join(COCO_PATH, 'annotations', 'instances_train2017.json')\n",
        "\n",
        "with open(coco_annotations_file, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "images = {img['id']: img for img in coco_data['images']}\n",
        "annotations = coco_data['annotations']\n",
        "\n",
        "image_to_labels = {}\n",
        "\n",
        "for ann in annotations:\n",
        "    image_id = ann['image_id']\n",
        "    category_id = ann['category_id']\n",
        "\n",
        "    if category_id not in COCO_CATEGORY_MAPPING:\n",
        "        continue\n",
        "\n",
        "    mapped_class = COCO_CATEGORY_MAPPING[category_id]\n",
        "\n",
        "    bbox = ann['bbox']\n",
        "    img_info = images[image_id]\n",
        "    img_width = img_info['width']\n",
        "    img_height = img_info['height']\n",
        "\n",
        "    x_center = (bbox[0] + bbox[2] / 2) / img_width\n",
        "    y_center = (bbox[1] + bbox[3] / 2) / img_height\n",
        "    width = bbox[2] / img_width\n",
        "    height = bbox[3] / img_height\n",
        "\n",
        "    label = f\"{mapped_class} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "    filename = img_info['file_name']\n",
        "    if filename not in image_to_labels:\n",
        "        image_to_labels[filename] = []\n",
        "    image_to_labels[filename].append(label)\n",
        "\n",
        "for filename, labels in tqdm(image_to_labels.items(), desc=\"Copying COCO images\"):\n",
        "    src_img = os.path.join(coco_images_dir, filename)\n",
        "    dest_img = os.path.join(MERGED_PATH, 'images', filename)\n",
        "    dest_lbl = os.path.join(MERGED_PATH, 'labels', filename.replace('.jpg', '.txt'))\n",
        "\n",
        "    if not os.path.exists(src_img):\n",
        "        continue\n",
        "\n",
        "    shutil.copyfile(src_img, dest_img)\n",
        "    with open(dest_lbl, 'w') as f:\n",
        "        f.write('\\n'.join(labels))\n",
        "\n",
        "    image_paths.append(dest_img)\n",
        "\n",
        "print(\"Processing RDD2022\")\n",
        "for split in ['train', 'test']:\n",
        "    rdd_images_dir = os.path.join(RDD_PATH, split, 'images')\n",
        "    rdd_labels_dir = os.path.join(RDD_PATH, split, 'labels')\n",
        "\n",
        "    if not os.path.exists(rdd_images_dir):\n",
        "        continue\n",
        "\n",
        "    for img_file in tqdm(os.listdir(rdd_images_dir), desc=f\"Copying {split} images\"):\n",
        "        if not img_file.endswith('.jpg'):\n",
        "            continue\n",
        "        src_img = os.path.join(rdd_images_dir, img_file)\n",
        "        src_lbl = os.path.join(rdd_labels_dir, img_file.replace('.jpg', '.txt'))\n",
        "\n",
        "        if not os.path.exists(src_lbl):\n",
        "            continue\n",
        "\n",
        "        dest_img = os.path.join(MERGED_PATH, 'images', img_file)\n",
        "        dest_lbl = os.path.join(MERGED_PATH, 'labels', img_file.replace('.jpg', '.txt'))\n",
        "\n",
        "        shutil.copyfile(src_img, dest_img)\n",
        "\n",
        "        with open(src_lbl, 'r') as f_in, open(dest_lbl, 'w') as f_out:\n",
        "            for line in f_in:\n",
        "                cls_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "                new_class_id = int(cls_id) + 4\n",
        "                f_out.write(f\"{new_class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "        image_paths.append(dest_img)\n",
        "\n",
        "# Splitting dataset\n",
        "random.shuffle(image_paths)\n",
        "train_split = int(0.7 * len(image_paths))\n",
        "val_split = int(0.9 * len(image_paths))\n",
        "\n",
        "with open(f\"{MERGED_PATH}/train.txt\", 'w') as f:\n",
        "    f.write('\\n'.join(image_paths[:train_split]))\n",
        "with open(f\"{MERGED_PATH}/val.txt\", 'w') as f:\n",
        "    f.write('\\n'.join(image_paths[train_split:val_split]))\n",
        "with open(f\"{MERGED_PATH}/test.txt\", 'w') as f:\n",
        "    f.write('\\n'.join(image_paths[val_split:]))\n",
        "\n",
        "print(\"Merged dataset ready at:\", MERGED_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f6611d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 48461 COCO images\n",
            "Found 15978 RDD images\n",
            "Balanced training file created: merged_dataset/train_balanced.txt\n",
            "Total training samples: 96395\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "train_txt_path = 'merged_dataset/train.txt'\n",
        "balanced_txt_path = 'merged_dataset/train_balanced.txt'\n",
        "\n",
        "coco_lines = []\n",
        "rdd_lines = []\n",
        "\n",
        "with open(train_txt_path, 'r') as f:\n",
        "    for line in f:\n",
        "        img_path = line.strip()\n",
        "        label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt').replace('\\\\', '/')\n",
        "\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(label_path, 'r') as label_file:\n",
        "                labels = label_file.readlines()\n",
        "                if not labels:\n",
        "                    continue\n",
        "                # Parse class IDs from label file\n",
        "                first_class = int(labels[0].split()[0])\n",
        "                if first_class < 4:\n",
        "                    coco_lines.append(line)\n",
        "                else:\n",
        "                    rdd_lines.append(line)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading label file {label_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "print(f\"Found {len(coco_lines)} COCO images\")\n",
        "print(f\"Found {len(rdd_lines)} RDD images\")\n",
        "\n",
        "# Oversample RDD images\n",
        "rdd_oversampled = rdd_lines * 3\n",
        "\n",
        "# Combine and shuffle\n",
        "import random\n",
        "all_lines = coco_lines + rdd_oversampled\n",
        "random.shuffle(all_lines)\n",
        "\n",
        "with open(balanced_txt_path, 'w') as f:\n",
        "    f.writelines(all_lines)\n",
        "\n",
        "print(f\"Balanced training file created: {balanced_txt_path}\")\n",
        "print(f\"Total training samples: {len(all_lines)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o-kpi0X12kGa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-kpi0X12kGa",
        "outputId": "4de2dab9-6057-43a5-f813-e014a4d4841e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Done!\n",
            "Train: 9340\n",
            "Val: 2001\n",
            "Test: 2001\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# balance dataset since there is an imbalance\n",
        "\n",
        "MERGED_PATH = \"merged_dataset\"\n",
        "labels_dir = os.path.join(MERGED_PATH, 'labels')\n",
        "images_dir = os.path.join(MERGED_PATH, 'images')\n",
        "\n",
        "train_small = os.path.join(MERGED_PATH, 'train_small.txt')\n",
        "val_small = os.path.join(MERGED_PATH, 'val_small.txt')\n",
        "test_small = os.path.join(MERGED_PATH, 'test_small.txt')\n",
        "\n",
        "target_per_class_train = 1000\n",
        "target_per_class_val = 300\n",
        "target_per_class_test = 300\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "class_to_images = defaultdict(set)\n",
        "all_images = []\n",
        "\n",
        "for label_file in os.listdir(labels_dir):\n",
        "    if not label_file.endswith('.txt'):\n",
        "        continue\n",
        "\n",
        "    label_path = os.path.join(labels_dir, label_file)\n",
        "    image_name = os.path.splitext(label_file)[0] + '.jpg'\n",
        "    image_path = os.path.join(images_dir, image_name)\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        continue\n",
        "\n",
        "    all_images.append(image_path)\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                cls = int(line.split()[0])\n",
        "                class_to_images[cls].add(image_path)\n",
        "\n",
        "def sample_subset(class_to_images, target_per_class):\n",
        "    selected = set()\n",
        "    for cls, images in class_to_images.items():\n",
        "        selected.update(random.sample(list(images), min(target_per_class, len(images))))\n",
        "    return list(selected)\n",
        "\n",
        "balanced_pool = sample_subset(class_to_images, target_per_class_train + target_per_class_val + target_per_class_test)\n",
        "random.shuffle(balanced_pool)\n",
        "\n",
        "val_count = int(len(balanced_pool) * val_ratio)\n",
        "test_count = int(len(balanced_pool) * test_ratio)\n",
        "\n",
        "val_images = balanced_pool[:val_count]\n",
        "test_images = balanced_pool[val_count:val_count + test_count]\n",
        "train_images = balanced_pool[val_count + test_count:]\n",
        "\n",
        "def write_list(path, images):\n",
        "    with open(path, 'w') as f:\n",
        "        f.writelines([img + '\\n' for img in sorted(images)])\n",
        "\n",
        "write_list(train_small, train_images)\n",
        "write_list(val_small, val_images)\n",
        "write_list(test_small, test_images)\n",
        "\n",
        "print(f\"Train: {len(train_images)}\\nVal: {len(val_images)}\\nTest: {len(test_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2005e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df2005e6",
        "outputId": "86ac7480-24fd-46f4-dc51-d9a9736b5453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.yaml written.\n"
          ]
        }
      ],
      "source": [
        "# ------------------ YAML FILE ------------------\n",
        "yaml_content = f\"\"\"\n",
        "path: C:/Users/tommy/Desktop/CMPE 258/RoadObjectDetection/merged_dataset\n",
        "train: train_small.txt\n",
        "val: val_small.txt\n",
        "test: test_small.txt\n",
        "\n",
        "nc: 9\n",
        "names: ['car', 'pedestrian', 'bicycle', 'truck', 'longitudinal crack', 'alligator crack', 'transverse crack', 'other corruption', 'pothole']\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open('dataset.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "print(\"dataset.yaml written.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ebca9434",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de26279",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2de26279",
        "outputId": "4d7464fc-6f10-4226-a500-0a6fc6734cb6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.nn.modules import C2f, Detect\n",
        "\n",
        "# Training\n",
        "device = 'cuda'\n",
        "\n",
        "model = YOLO('yolov8_custom.yaml')\n",
        "\n",
        "model.train(\n",
        "    data='dataset.yaml',\n",
        "    epochs=100,\n",
        "    imgsz=480,  \n",
        "    batch=8,\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.001,\n",
        "    weight_decay=0.0005,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    translate=0.05,\n",
        "    scale=0.4,\n",
        "    shear=0.4,\n",
        "    perspective=0.0003,\n",
        "    fliplr=0.3,\n",
        "    mosaic=0.25,\n",
        "    device='cuda',\n",
        "    project='experiments',\n",
        "    name='Custom_Model'\n",
        ")\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e583214",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.126  Python-3.10.2 torch-2.7.0+cu118 CPU (Intel Core(TM) i7-10700F 2.90GHz)\n",
            "YOLOv8_custom summary (fused): 90 layers, 18,674,915 parameters, 0 gradients, 45.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 12.05.0 MB/s, size: 79.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning merged_dataset\\labels... 2001 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2001/2001 [00:03<00:00, 590.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: merged_dataset\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 126/126 [03:53<00:00,  1.86s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       2001       9274      0.563       0.45      0.463      0.242\n",
            "                   car        440       1651      0.647      0.434      0.477       0.27\n",
            "            pedestrian        675       3508      0.692      0.467      0.523       0.28\n",
            "               bicycle        258        580      0.525      0.378      0.386      0.215\n",
            "                 truck        337        530      0.532      0.394      0.409      0.248\n",
            "    longitudinal crack        479        925      0.511       0.38      0.382      0.181\n",
            "       alligator crack        375        574      0.491      0.423      0.415      0.176\n",
            "      transverse crack        419        545      0.547      0.523      0.524      0.269\n",
            "      other corruption        375        522      0.572      0.655      0.623      0.358\n",
            "               pothole        267        439      0.549      0.394      0.431      0.183\n",
            "Speed: 0.6ms preprocess, 105.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mc:\\Users\\tommy\\runs\\detect\\val15\u001b[0m\n",
            "mAP@0.5: 0.4632\n",
            "mAP@0.5:0.95: 0.2421\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"C:/Users/tommy/Desktop/CMPE 258/RoadObjectDetection/experiments/Custom_Model3/weights/best.pt\")\n",
        "\n",
        "metrics = model.val(data='dataset.yaml', split='test', device = 'cpu')\n",
        "\n",
        "\n",
        "print(f\"mAP@0.5: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95: {metrics.box.map:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c26db1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 C:\\Users\\tommy\\Desktop\\CMPE 258\\RoadObjectDetection\\RDD_SPLIT\\test\\images\\Japan_006154.jpg: 480x480 2 trucks, 58.4ms\n",
            "Speed: 1.7ms preprocess, 58.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 480)\n",
            "Results saved to \u001b[1mc:\\Users\\tommy\\runs\\detect\\predict7\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"C:/Users/tommy/Desktop/CMPE 258/RoadObjectDetection/experiments/AdamW_V2/weights/best.pt\")\n",
        "results = model.predict(\n",
        "    source='C:/Users/tommy/Desktop/CMPE 258/RoadObjectDetection/RDD_SPLIT/test/images/Japan_006154.jpg',\n",
        "    save=True,\n",
        "    device='cpu'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
